---
layout: mypost
title: PCIe流量控制
categories: [PCIe]
---

流量控制的机制最初来自于互联网中，在一个网络中主要包含两类资源，数据通路和数据缓冲。数据通路是最珍贵的资源，它决定了网络的最大带宽。数据缓冲区也很重要，当数据在网络上传输时，它是从一个节点传到另一个节点时中间需要经过若干节点才能到达目的地。每个节点中都含有缓冲区，暂存这个节点中没有处理完的数据。网络设备使用这些缓冲区可以搭建数据传送的流水线从而提高数据传输性能。最初在网络节点中只为一条链路提供了一个缓冲区，后来有引入了多个多虚拟通路（VC）缓冲区，不同的报文可以使用不同的通路进行传递，从而提高了传输效率。目前的流量控制的实现主要是基于多通道技术，它的主要作用是合理的利用物理链路，避免因接收端缓冲区不足导致数据包的丢弃和重发，从而有效的使用网络贷款。它的核心原理都是通过根据接收端缓冲区的容量，向发送端提供反馈，发送端根据该反馈决定发送多少数据。

在PCIe总线中，当一个发送端发送数据报文给接收端时，它需要保证接收端有足够的缓冲区。为了能够知道接收端还有多少可用的缓冲区，接收端需要通过DLLP (Data Link Layer Packet）随时汇报可用的缓冲区。

![FCDLLP](FCDLLP.png)

PCIe总线使用的流控算法叫做基于信用的流量控制机制（Credit-based Mechanism）。接收端的可用缓冲数量使用信用积分来表示，接收端通过不断的发送DLLP告知接收端VC buffer的信用数，当缓冲区用尽时发送端会停止发送TLP以防数据包丢弃和重发。

PCIe设备发送的数据是以TLP形式发出的，TLP通过数据链路层，而达到数据缓存时被分解为Header和Data两个部分，分别存放到不同的接收缓冲队列中。
1. PH缓存存放Memory Writes和Messages请求的TLP 头
2. PD缓存存放Memory Writes和Messages请求的TLP 数据；
3. NPH缓存存放Non-Posted请求的TLP 头；
4. NPD缓存存放Non-Posted请求的TLP 数据；
5. CPLH缓存存放Read/Wirte Completions请求的TLP 头；
6. CPLD缓存存放Read/Wirte Completions请求的TLP 数据；

![FCBORG](FCBORG.png)

PCIe对于每种不同类型的Header和Data使用不同的Credit值，PCIe总线规范并没有规定如何设置Credit，但是规定了初始化之后的最小值。

![CREDITSZ](CREDITSZ.png)

PCIe总线将Header和Data缓存分离的主要原因是，通常TLP的Header的大小是固定的但是Data的大小并不固定，Data的长度通常由TLP的Length字段确定。将Header和Data缓存分离有利于合理利用Data缓存。

因为TLP的传输需要知道接收端的可用的Credit Buffer，所以要先对接收端和发送端的Flow Control进行初始化也就是初始化它们的Credit Buffer。Flow Control的初始化是在链路训练完成之后，当物理层的LinkUp信号触发之后就会开始，这个过程也被称为DLCMSM(Data Link Control and Management State Machine)。

![LNKUP](LNKUP.png)

PCIe总线的数据链路层共有三个状态，分别为DL_Inactive（表示链路无效状态，不可用，或者没有连接设备）。DL_Init（链路可用，将进行VC0的初始化）。DL_Active（链路可正常使用）。

![DLCMSM](DLCMSM.png)

在各个节点能够正常使用前，首先要对VC0进行初始化。当VC0初始化完成以后，PCIe设备就可以对VC1~7进行初始化。当前节点进入DL_Init时先会进入FC_INIT1阶段，这时设备会发送3个InitFC1 FCP(DLLP的一种）初始化接收端的VC Buffer。

![FC_INIT1](FC_INIT1.png)

这三个FCP分别为Posted, Non Posted, Completion。

![FCP](FCP.png)

PCIe总线还提供了FC_INIT2状态，它主要是用来验证FC_INIT1的结果。当节点进入FC_INIT2状态时，与流量控制相关性的缓存已经初始化完毕。在成功发送完3个FC_INIT2 FCP之后，数据链路层进入DL_acvitve并通知事务层DL_UP，事务层可以发送TLP了。

参考：

《PCI-SIG SR-IOV Primer》

《Single Root I/O Virtualization and Sharing Specification Revision 1.1》
